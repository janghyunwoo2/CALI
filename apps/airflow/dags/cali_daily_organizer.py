import os
import re
import json
import requests
import gzip  # [ì¶”ê°€] ì••ì¶• í•´ì œìš©
from datetime import datetime, timedelta
from airflow import DAG
from airflow.providers.amazon.aws.hooks.s3 import S3Hook
from airflow.operators.python import PythonOperator

# --- [1. ì„¤ì •] ---
BUCKET_NAME = os.getenv('S3_BACKUP_BUCKET') or "cali-logs-827913617635"
LANDING_ZONE = 'raw/'
STATS_ZONE = 'daily_stats/'
SLACK_WEBHOOK_URL = os.getenv('SLACK_WEBHOOK_URL')

default_args = {
    'owner': 'cali_admin',
    'start_date': datetime(2026, 1, 28),
    'retries': 1,
}

# --- [2. ì—ëŸ¬ ë¶„ë¥˜ê¸°] ---
def classify_error_type(content):
    c = content.lower()
    if any(k in c for k in ['db_cache', 'db_issue', 'database']):
        return 'Database'
    elif any(k in c for k in ['infra', 'eks', 'kubernetes']):
        return 'Infra_EKS'
    elif any(k in c for k in ['payment', 'pg']):
        return 'Payment'
    elif any(k in c for k in ['auth', 'security']):
        return 'Auth_Security'
    elif any(k in c for k in ['business', 'logic', 'microservice']):
        return 'BusinessLogic'
    return 'Other_Errors'

# --- [3. ë©”ì¸ ë¶„ì„ ë° ìŠ¬ë™ ì „ì†¡ í•¨ìˆ˜] ---
def daily_analysis_and_slack(**context):
    s3_hook = S3Hook(aws_conn_id='aws_default')
    all_keys = s3_hook.list_keys(bucket_name=BUCKET_NAME, prefix=LANDING_ZONE)
    
    if not all_keys:
        print("ğŸ“¢ ë¶„ì„í•  ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    clean_keys = [k for k in all_keys if k != LANDING_ZONE and not k.endswith('/')]
    
    category_counts = {
        "Database": 0, "Infra_EKS": 0, "Payment": 0, 
        "Auth_Security": 0, "BusinessLogic": 0
    }
    total_logs = 0
    total_errors = 0
    date_str = datetime.now().strftime('%Y-%m-%d')

    for key in clean_keys:
        # [ìˆ˜ì •] read_key ëŒ€ì‹  ì§ì ‘ ë°”ì´íŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ ì••ì¶• ì—¬ë¶€ íŒë‹¨
        file_obj = s3_hook.get_key(key, BUCKET_NAME)
        raw_content = file_obj.get()['Body'].read()
        total_logs += 1

        try:
            # Gzip íŒŒì¼ì¸ ê²½ìš° í•´ì œ ì‹œë„ (0x1f 0x8b í—¤ë” í™•ì¸)
            if raw_content.startswith(b'\x1f\x8b'):
                content = gzip.decompress(raw_content).decode('utf-8')
            else:
                content = raw_content.decode('utf-8')
        except Exception as e:
            print(f"âŒ {key} ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            continue
        
        if "ERROR" in content.upper():
            total_errors += 1
            category = classify_error_type(content)
            if category in category_counts:
                category_counts[category] += 1

    # [íŒŒì¼ ì €ì¥]
    for category, count in category_counts.items():
        summary_data = {"date": date_str, "category": category, "error_count": count}
        target_key = f"{STATS_ZONE}{category}/{date_str}_stats.json"
        
        s3_hook.load_string(
            string_data=json.dumps(summary_data, ensure_ascii=False),
            key=target_key,
            bucket_name=BUCKET_NAME,
            replace=True
        )

    send_daily_slack_report(date_str, total_logs, total_errors, category_counts)

def send_daily_slack_report(date_str, total, errors, counts):
    if not SLACK_WEBHOOK_URL: return

    detail_msg = "\n".join([f"â€¢ {cat}: {cnt}ê±´" for cat, cnt in counts.items()])
    
    payload = {
        "text": f"ğŸ“… *{date_str} ì¼ì¼ ë¡œê·¸ ë¶„ì„ ìš”ì•½*",
        "attachments": [{
            "color": "#FF0000" if errors > 0 else "#00FF00",
            "blocks": [
                {
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": f"*ì´ ë¡œê·¸ ìˆ˜:* {total}ê±´\n*ì´ ì—ëŸ¬ ë°œìƒ:* {errors}ê±´"}
                },
                {
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": f"*ì¹´í…Œê³ ë¦¬ë³„ ì—ëŸ¬ ìƒì„¸:*\n{detail_msg}"}
                }
            ]
        }]
    }
    requests.post(SLACK_WEBHOOK_URL, data=json.dumps(payload))

# --- [4. DAG ì •ì˜] ---
with DAG(
    dag_id='cali_daily_stats_reporter',
    default_args=default_args,
    schedule='@daily', 
    catchup=False,
    tags=['report', 'daily', 'slack']
) as dag:

    run_analysis = PythonOperator(
        task_id='daily_safe_analysis_task',
        python_callable=daily_analysis_and_slack
    )