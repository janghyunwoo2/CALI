import os
import requests
import json
from datetime import datetime, timedelta
from airflow import DAG
from airflow.providers.amazon.aws.sensors.s3 import S3KeySensor 
from airflow.providers.amazon.aws.hooks.s3 import S3Hook 
from airflow.operators.python import PythonOperator 

# 1. í™˜ê²½ ì„¤ì •
BUCKET_NAME = os.getenv('S3_BACKUP_BUCKET')
SOLUTIONS_PREFIX = 'solutions/'
PROCESSED_PREFIX = 'processed/'
SLACK_WEBHOOK_URL = os.getenv('SLACK_WEBHOOK_URL')

MILVUS_HOST = os.getenv('MILVUS_HOST', 'milvus-standalone')
MILVUS_PORT = '19530'
COLLECTION_NAME = 'cali_rag_collection'
SIMILARITY_THRESHOLD = 0.1  # L2 ê±°ë¦¬ ê¸°ì¤€ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë˜‘ê°™ìŒ)

default_args = {
    'owner': 'cali_admin',
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    dag_id='cali_rag_unified_pipeline',
    default_args=default_args,
    start_date=datetime(2026, 1, 27),
    schedule_interval=None,
    catchup=False,
    tags=['cali', 'rag', 'milvus']
) as dag:

    wait_for_file = S3KeySensor(
        task_id='wait_for_s3_file',
        bucket_name=BUCKET_NAME,
        bucket_key=f'{SOLUTIONS_PREFIX}*.txt',
        wildcard_match=True,
        timeout=60 * 60 * 12,
        poke_interval=10,
        mode='poke'
    )

    def process_cali_rag_logic(**context):
        # --- [ì¤‘ìš”] ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì„ ë•Œ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì£½ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ import ---
        from pymilvus import connections, Collection, utility
        from sentence_transformers import SentenceTransformer
        
        s3_hook = S3Hook(aws_conn_id='aws_default')
        
        all_files = s3_hook.list_keys(bucket_name=BUCKET_NAME, prefix=SOLUTIONS_PREFIX)
        txt_files = [f for f in all_files if f.endswith('.txt') and f != SOLUTIONS_PREFIX]
        
        if not txt_files:
            raise ValueError("S3ì— ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            
        target_file = txt_files[0]
        content = s3_hook.read_key(target_file, BUCKET_NAME)
        
        if len(content.strip()) < 20:
            s3_hook.delete_objects(bucket=BUCKET_NAME, keys=target_file)
            raise ValueError(f"âŒ ë‚´ìš© ë¶€ì‹¤ ë°ì´í„° ì‚­ì œ ì™„ë£Œ: {target_file}")

        try:
            # 1. Milvus ì—°ê²° ë° ëª¨ë¸ ë¡œë“œ
            connections.connect("default", host=MILVUS_HOST, port=MILVUS_PORT)
            model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-aug')
            vector = model.encode(content).tolist()
            
            collection = Collection(COLLECTION_NAME)
            collection.load() # ê²€ìƒ‰ì„ ìœ„í•´ ë©”ëª¨ë¦¬ ë¡œë“œ

            # 2. [ì¶”ê°€] ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•œ ì¤‘ë³µ ì²´í¬
            search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
            results = collection.search(
                data=[vector], 
                anns_field="vector", 
                param=search_params, 
                limit=1,
                output_fields=["raw_text"]
            )

            is_duplicate = False
            if results and len(results[0]) > 0:
                hit = results[0][0]
                # L2 ê±°ë¦¬ê°€ ë„ˆë¬´ ê°€ê¹Œìš°ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
                if hit.distance < SIMILARITY_THRESHOLD:
                    is_duplicate = True
                    print(f"âš ï¸ ì¤‘ë³µ ê°ì§€: ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì§€ì‹ì…ë‹ˆë‹¤. (Distance: {hit.distance})")

            # 3. ì¤‘ë³µì´ ì•„ë‹ ë•Œë§Œ ì ì¬
            if not is_duplicate:
                data = [[vector], [content]]
                collection.insert(data)
                collection.flush()
                print(f"ğŸš€ Milvus ì ì¬ ì„±ê³µ: {target_file}")
            else:
                print(f"â­ ì¤‘ë³µ ë°ì´í„°ë¼ ì ì¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"âŒ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise e
        finally:
            connections.disconnect("default")

        # [íŒŒì¼ ì •ë¦¬]
        dest_key = target_file.replace(SOLUTIONS_PREFIX, PROCESSED_PREFIX)
        s3_hook.copy_object(
            source_bucket_key=target_file, dest_bucket_key=dest_key,
            source_bucket_name=BUCKET_NAME, dest_bucket_name=BUCKET_NAME
        )
        s3_hook.delete_objects(bucket=BUCKET_NAME, keys=target_file)
        print(f"ğŸ“¦ ì´ë™ ì™„ë£Œ: {target_file} -> {dest_key}")

    run_main_logic = PythonOperator(
        task_id='run_cali_main_logic',
        python_callable=process_cali_rag_logic
    )

    def send_report(**context):
        msg = "âœ… [cali í”„ë¡œì íŠ¸] RAG ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ! (ì¤‘ë³µ ì²´í¬ í¬í•¨) ğŸš€"
        if SLACK_WEBHOOK_URL:
            requests.post(SLACK_WEBHOOK_URL, data=json.dumps({"text": msg}))

    notify_complete = PythonOperator(
        task_id='notify_complete',
        python_callable=send_report
    )

    wait_for_file >> run_main_logic >> notify_complete