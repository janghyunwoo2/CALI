import os
import requests
import json
import subprocess
import sys
from datetime import datetime, timedelta
from airflow import DAG
from airflow.providers.amazon.aws.sensors.s3 import S3KeySensor 
from airflow.providers.amazon.aws.hooks.s3 import S3Hook 
from airflow.operators.python import PythonOperator 
from airflow.models import Variable

# --- [1. ìƒìˆ˜ ì„¤ì •] ---
# S3 ë²„í‚· ì´ë¦„ (ì‹¤ì œ ë¦¬ì†ŒìŠ¤ ì´ë¦„ê³¼ ì¼ì¹˜í•´ì•¼ í•¨)
BUCKET_NAME = "cali-logs-827913617635" 
# Milvus ì„œë²„ ì£¼ì†Œ (K8s ë‚´ë¶€ DNS í’€ë„¤ìž„ ì‚¬ìš©ìœ¼ë¡œ ë„¤ìž„ìŠ¤íŽ˜ì´ìŠ¤ ê°„ í†µì‹  ë³´ìž¥)
MILVUS_HOST = "milvus-standalone.milvus.svc.cluster.local"
MILVUS_PORT = "19530"
# ì €ìž¥í•  Milvus ì»¬ë ‰ì…˜ ì´ë¦„ (ê¸°ì¡´ MilvusClientì™€ ì‹±í¬ ë§žì¶¤)
COLLECTION_NAME = "cali_rag_collection"
# ì•Œë¦¼ìš© ìŠ¬ëž™ ì›¹í›… (í˜„ìž¬ëŠ” ë¹„ì–´ìžˆìŒ)
SLACK_WEBHOOK_URL = ""

# S3 ë‚´ íŒŒì¼ ê²½ë¡œ ê´€ë¦¬ (ê°ì‹œ í´ë” vs ì™„ë£Œ í´ë”)
SOLUTIONS_PREFIX = 'solutions/'
PROCESSED_PREFIX = 'processed/'

# DAGì˜ ê¸°ë³¸ ì„¤ì • (ì‹¤íŒ¨ ì‹œ ëŒ€ì‘ ë¡œì§)
default_args = {
    'owner': 'cali_admin',
    'retries': 2,                  # ì‹¤íŒ¨í•˜ë©´ ë”± 2ë²ˆë§Œ ë” í•´ë³´ìž (ë¦¬íŠ¸ë¼ì´)
    'retry_delay': timedelta(seconds=30), # ì‹¤íŒ¨ ì‹œ 30ì´ˆ ëŒ€ê¸° í›„ ë°”ë¡œ ìž¬ì‹œë„ (ìŠ¤í”¼ë“œê°€ ìƒëª…)
}

# DAG ì •ì˜ (ID, ì‹œìž‘ì¼, ìŠ¤ì¼€ì¤„ ë“±)
with DAG(
    dag_id='cali_rag_unified_pipeline',
    default_args=default_args,
    start_date=datetime(2026, 1, 27),
    schedule_interval=None,         # ìˆ˜ë™ìœ¼ë¡œ íŠ¸ë¦¬ê±°í•˜ê±°ë‚˜ ì„¼ì„œê°€ ìž¡ì„ ë•Œë§Œ ì‹¤í–‰
    catchup=False,                  # ê³¼ê±° ë¯¸ì‹¤í–‰ë¶„ ë¬´ì‹œ
    tags=['cali', 'rag', 'milvus', 'openai'] # UIì—ì„œ ì°¾ê¸° íŽ¸í•˜ê²Œ íƒœê·¸ ë‹¬ê¸°
) as dag:

    # --- [íƒœìŠ¤í¬ 1: S3 íŒŒì¼ ê°ì‹œ] ---
    # ì§€ì •ëœ ë²„í‚·ì˜ solutions/ í´ë”ì— .txt íŒŒì¼ì´ ë“¤ì–´ì˜¤ëŠ”ì§€ ê°ì‹œ
    wait_for_file = S3KeySensor(
        task_id='wait_for_s3_file',
        bucket_name=BUCKET_NAME,
        bucket_key=f'{SOLUTIONS_PREFIX}*.txt', # ì™€ì¼ë“œì¹´ë“œ ë§¤ì¹­ìœ¼ë¡œ ëª¨ë“  txt ê°ì‹œ
        wildcard_match=True,
        timeout=60 * 30,              # 30ë¶„ ë™ì•ˆ ì•ˆ ì˜¤ë©´ "íŒŒì¼ ì•ˆ ì™”ìŒ" ì‹¤íŒ¨ ì²˜ë¦¬
        poke_interval=30,             # 30ì´ˆë§ˆë‹¤ í•œ ë²ˆì”© S3 ë¬¸ ë‘ë“œë¦¬ê¸°
        mode='reschedule',            # í•µì‹¬! ëŒ€ê¸° ì¤‘ì—ëŠ” Workerë¥¼ ë¹„ì›Œì¤˜ì„œ ë‹¤ë¥¸ ìž‘ì—… ê°€ëŠ¥í•˜ê²Œ í•¨
        exponential_backoff=True      # ê³„ì† ì—†ìœ¼ë©´ í™•ì¸ ê°„ê²©ì„ ì¡°ê¸ˆì”© ëŠ˜ë ¤ê°€ëŠ” ì§€ëŠ¥í˜• ì„¼ì„œ
    )

    # --- [í•µì‹¬ ë¡œì§: ë°ì´í„° ê°€ê³µ ë° Milvus ì ìž¬] ---
    def process_cali_rag_logic(**context):
        # ëŸ°íƒ€ìž„ ì¤‘ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìžë™ ì„¤ì¹˜ ìœ í‹¸ë¦¬í‹°
        def install_and_import(package):
            try:
                __import__(package)
            except ImportError:
                # ì—ì–´í”Œë¡œìš° ì´ë¯¸ì§€ì— ì—†ìœ¼ë©´ pipë¡œ ì¦‰ì‹œ ì„¤ì¹˜ (ìœ ì—°ì„± í™•ë³´)
                subprocess.check_call([sys.executable, "-m", "pip", "install", package])
        
        # OpenAI í†µì‹  ë° Milvus í•¸ë“¤ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
        install_and_import('openai')
        install_and_import('pymilvus')
        
        from openai import OpenAI
        from pymilvus import connections, Collection

        # Airflow UIì— ìˆ¨ê²¨ë‘” OpenAI API í‚¤ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
        try:
            api_key = Variable.get("OPENAI_API_KEY")
        except Exception as e:
            raise ValueError(f"Variable 'OPENAI_API_KEY' ëˆ„ë½: {e}")
        
        # S3 ì¡°ìž‘ì„ ìœ„í•œ Hook (ì‹ ë¶„ì¦ ì—­í• )
        s3_hook = S3Hook()
        # solutions/ í´ë” ë‚´ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ í™•ë³´
        all_files = s3_hook.list_keys(bucket_name=BUCKET_NAME, prefix=SOLUTIONS_PREFIX)
        txt_files = [f for f in all_files if f.endswith('.txt') and f != SOLUTIONS_PREFIX]
        
        if not txt_files:
            return # íŒŒì¼ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì¢…ë£Œ (ì„¼ì„œ ì˜¤ìž‘ë™ ë°©ì§€)
            
        target_file = txt_files[0]
        # S3ì—ì„œ íŒŒì¼ ë‚´ìš© ì½ì–´ì˜¤ê¸°
        raw_content = s3_hook.read_key(target_file, BUCKET_NAME)
        
        # ë°ì´í„°ê°€ JSONì´ë©´ íŒŒì‹±, ì•„ë‹ˆë©´ í…ìŠ¤íŠ¸ë¥¼ ì ì ˆížˆ ìª¼ê°œê¸°
        try:
            log_data = json.loads(raw_content)
        except:
            # ì¤„ê¸€ì¼ ê²½ìš° Milvus ìŠ¤í‚¤ë§ˆ(service, message, cause, action)ì— ë§žì¶° ê°€ê³µ
            log_data = {
                "service": "manual",
                "message": raw_content[:100], # ì œëª©ì²˜ëŸ¼ ì“¸ 100ìž
                "cause": "N/A",
                "action": raw_content         # ì „ì²´ ë‚´ìš©ì„ actionì— ì €ìž¥
            }

        # OpenAI API í˜¸ì¶œ: í…ìŠ¤íŠ¸ë¥¼ 1536ì°¨ì› ë²¡í„° ìˆ«ìžë¡œ ë³€í™˜
        ai_client = OpenAI(api_key=api_key)
        response = ai_client.embeddings.create(
            model="text-embedding-3-small",
            input=log_data.get("message", "") # ì—ëŸ¬ ìš”ì•½ë³¸ì„ ë²¡í„°ë¡œ ë§Œë“¦
        )
        vector = response.data[0].embedding

        try:
            # Milvus ì„œë²„ ì—°ê²°
            connections.connect("default", host=MILVUS_HOST, port=MILVUS_PORT)
            collection = Collection(COLLECTION_NAME)
            
            # [ì¤‘ë³µ ì œê±° ë‹¨ê³„] ë™ì¼ ì„œë¹„ìŠ¤ + ë™ì¼ ë©”ì‹œì§€ê°€ ìžˆìœ¼ë©´ ê¸°ì¡´ ê±° ì‚­ì œ
            svc = log_data.get("service", "unknown").replace("'", "\\'")
            msg = log_data.get("message", "").replace("'", "\\'")
            delete_expr = f"service == '{svc}' && error_message == '{msg}'"
            collection.delete(delete_expr)
            collection.flush() # ì‚­ì œ ì™„ë£Œ í™•ì •
            
            # [ì ìž¬ ë‹¨ê³„] MilvusClient ìŠ¤í‚¤ë§ˆì— ë§žì¶° ë°ì´í„° êµ¬ì„±
            row = {
                "vector": vector,                                # ë³€í™˜ëœ ë²¡í„°ê°’
                "service": log_data.get("service", "unknown")[:64],
                "error_message": log_data.get("message", "")[:1024],
                "cause": log_data.get("cause", "")[:2048],
                "action": log_data.get("action", "")[:2048],
            }
            
            collection.insert([row]) # í–‰ ë‹¨ìœ„ ì‚½ìž…
            collection.flush()       # ì €ìž¥ ì™„ë£Œ í™•ì •
            print(f"ðŸš€ Milvus ì ìž¬ ì™„ë£Œ: {target_file}")
            
        finally:
            connections.disconnect("default") # í†µì‹  ëë‚¬ìœ¼ë©´ ë§¤ë„ˆ ìžˆê²Œ ëŠê¸°

        # [ë§ˆë¬´ë¦¬ ë‹¨ê³„] ì²˜ë¦¬ ì™„ë£Œëœ íŒŒì¼ì„ processed/ í´ë”ë¡œ ì´ë™ (S3 ì •ë¦¬)
        dest_key = target_file.replace(SOLUTIONS_PREFIX, PROCESSED_PREFIX)
        s3_hook.copy_object(source_bucket_key=target_file, dest_bucket_key=dest_key, 
                            source_bucket_name=BUCKET_NAME, dest_bucket_name=BUCKET_NAME)
        s3_hook.delete_objects(bucket=BUCKET_NAME, keys=target_file) # ì›ë³¸ ì‚­ì œ

    # ì‹¤ì œ íŒŒì´ì¬ ë¡œì§ ì‹¤í–‰ íƒœìŠ¤í¬
    run_main_logic = PythonOperator(
        task_id='run_cali_main_logic',
        python_callable=process_cali_rag_logic
    )

    # ìŠ¬ëž™ ì•Œë¦¼ ì „ì†¡ (ì„ íƒ ì‚¬í•­)
    def send_report(**context):
        if SLACK_WEBHOOK_URL:
            msg = "âœ… [Cali RAG] ì—…ë°ì´íŠ¸ ì™„ë£Œ!"
            requests.post(SLACK_WEBHOOK_URL, data=json.dumps({"text": msg}))

    notify_complete = PythonOperator(task_id='notify_complete', python_callable=send_report)

    # íƒœìŠ¤í¬ ìˆœì„œ ê²°ì •: ê°ì‹œ -> ë¡œì§ ì‹¤í–‰ -> ì•Œë¦¼
    wait_for_file >> run_main_logic >> notify_complete