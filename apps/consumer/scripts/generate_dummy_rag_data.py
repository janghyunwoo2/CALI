import sys
import os
import glob
import re
import sys
import os
import glob
import re
# import yaml (Removed to avoid dependency issues)
from typing import List, Dict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.milvus_client import MilvusClient
from services.openai_client import OpenAIClient
from utils.logger import setup_logger
from utils.text_preprocessor import clean_log_for_embedding

logger = setup_logger(__name__)

KB_DIR = "knowledge_base"

def parse_yaml_manually(yaml_text):
    """PyYAML ì—†ì´ ê°„ë‹¨í•œ í‚¤-ê°’ íŒŒì‹±"""
    metadata = {}
    for line in yaml_text.splitlines():
        if ":" in line:
            key, val = line.split(":", 1)
            metadata[key.strip()] = val.strip()
    return metadata

def parse_markdown_kb_multi(file_path):
    """MD íŒŒì¼ íŒŒì‹± (seed_milvus.py ë¡œì§ ì¬ì‚¬ìš©)"""
    cases = []
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            full_text = f.read()

        pattern = re.compile(r"## \d+\..+?(?=## \d+\.|$)", re.DOTALL)
        sections = pattern.findall(full_text)
        
        for section in sections:
            try:
                yaml_match = re.search(r"---\n(.+?)\n---", section, re.DOTALL)
                if not yaml_match: continue
                
                # metadata = yaml.safe_load(yaml_match.group(1))
                metadata = parse_yaml_manually(yaml_match.group(1))
                
                body_text = section.replace(yaml_match.group(0), "")
                
                summary = ""
                cause = "ë¶„ì„ ì¤‘..."
                action = "ë‚´ìš© ì—†ìŒ"
                
                parts = body_text.split("### Root Cause")
                if len(parts) > 1:
                    summary = parts[0].replace("### Incident Summary", "").strip()
                    remaining = parts[1]
                    if "### Action Items" in remaining:
                        c, a = remaining.split("### Action Items")
                        cause = c.strip()
                        action = a.strip()
                    else:
                        cause = remaining.strip()
                
                cases.append({
                    "service": metadata.get("service", "unknown"),
                    "message": metadata.get("error_message", "unknown error"),
                    "log_content": summary,
                    "cause": cause,
                    "action": action
                })
            except: continue
    except: pass
    return cases

SYSTEM_PROMPT_GENERATOR = """
You are a Synthetic Log Data Generator for a SRE Knowledge Base.
Your task is to generate realistic variations of a given error log scenario.

Input Format:
- Service: <service_name>
- Original Error: <error_message>
- Context: <summary_and_cause>

Output Format (JSON List):
[
    {
        "message": "Varied error message 1",
        "log_content": "Multi-line stack trace conforming to Java/Python/Go standard..."
    },
    ...
]

Rules:
1. Generate 3 unique variations.
2. Maintain the same technical root cause but vary the specific error phrasing, timestamps, thread names, or variable values.
3. 'log_content' must be a realistic stack trace or log block (at least 3-5 lines).
"""

def generate_variations(ai_client, case) -> List[Dict]:
    """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í˜• ë°ì´í„° ìƒì„±"""
    prompt = f"""
    Service: {case['service']}
    Original Error: {case['message']}
    Context: {case['log_content']} / Cause: {case['cause']}
    """
    
    try:
        # OpenAI Completion API í˜¸ì¶œ (JSON ëª¨ë“œ ê¶Œì¥)
        # OpenAIClient.analyze_log ë“±ì„ ìš°íšŒí•˜ì—¬ ì§ì ‘ client í˜¸ì¶œì´ í•„ìš”í•˜ë‚˜, 
        # ì—¬ê¸°ì„œëŠ” analyze_log êµ¬ì¡°ë¥¼ ë¹Œë ¤ì“°ê±°ë‚˜ client.client.chat.completionsë¥¼ ì”ë‹ˆë‹¤.
        # OpenAIClient êµ¬ì¡°ìƒ client ì†ì„± ì ‘ê·¼ ê°€ëŠ¥í•˜ë‹¤ê³  ê°€ì •.
        
        response = ai_client.client.chat.completions.create(
            model="gpt-4-turbo-preview",  # ë˜ëŠ” gpt-3.5-turbo-0125
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT_GENERATOR},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}
        )
        
        import json
        content = response.choices[0].message.content
        data = json.loads(content)
        # ì˜ˆìƒ í¬ë§·: {"variations": [...]} or list directly
        # í”„ë¡¬í”„íŠ¸ì—ì„œ listë¥¼ ìš”ì²­í–ˆìœ¼ë¯€ë¡œ { "variations": [...] } í˜•íƒœë¡œ ë°›ë„ë¡ ìœ ë„í•˜ê±°ë‚˜ íŒŒì‹±
        
        # ì•ˆì „í•œ íŒŒì‹±
        if isinstance(data, list): return data
        if "variations" in data: return data["variations"]
        return []
        
    except Exception as e:
        logger.error(f"Generation failed: {e}")
        return []

def run_generator():
    print("ğŸš€ Synthetic Data Generator Started...")
    milvus = MilvusClient()
    ai = OpenAIClient()
    
    md_files = glob.glob(os.path.join(KB_DIR, "*.md"))
    total_generated = 0
    
    for file_path in md_files:
        print(f"Reading {os.path.basename(file_path)}...")
        cases = parse_markdown_kb_multi(file_path)
        
        for case in cases:
            print(f"  - Generating variants for: {case['message'][:30]}...")
            variations = generate_variations(ai, case)
            
            for v in variations:
                # ë©”íƒ€ë°ì´í„°ëŠ” ì›ë³¸ ìœ ì§€ (Cause/Actionì€ ë™ì¼í•˜ë¯€ë¡œ RAG ì •ë‹µë¥  ìƒìŠ¹)
                new_case = case.copy()
                new_case['message'] = v['message']
                new_case['log_content'] = v['log_content']
                new_case['is_synthetic'] = True
                
                # ì„ë² ë”© & ì €ì¥
                clean_text = clean_log_for_embedding(
                    new_case['service'], new_case['message'], new_case['log_content']
                )
                full_context = f"{clean_text} \nCause: {new_case['cause']} \nAction: {new_case['action']}"
                
                vector = ai.create_embedding(full_context) # ì²­í‚¹ ì—†ì´ ì „ì²´ 1ê°œë¡œ ì €ì¥
                milvus.insert_log_case(new_case, vector, flush=False)
                total_generated += 1
                
    milvus.flush_collection()
    print(f"âœ… Generated & Inserted {total_generated} synthetic records.")

if __name__ == "__main__":
    run_generator()
