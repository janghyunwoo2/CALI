"""
=====================================================
Kinesis Stream Consumer
=====================================================
ì„¤ëª…: Kinesis Data Streamì—ì„œ ë¡œê·¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ êµ¬ë…
ì—­í• : ë°ì´í„° ìˆ˜ì‹  â†’ Pydantic ê²€ì¦ â†’ RAG ë¶„ì„ â†’ Slack ì•Œë¦¼
=====================================================
"""

import json
import time
from typing import Any, Dict, List

import boto3
from config.settings import settings
from models.log_schema import LogRecord
from pydantic import ValidationError
from services.milvus_client import MilvusClient
from services.openai_client import AIClient
from services.s3_dlq import S3DLQ
from services.slack_notifier import SlackNotifier
from services.throttle import Throttle
from utils.logger import setup_logger
from utils.text_preprocessor import clean_log_for_embedding

logger = setup_logger(__name__)


class KinesisConsumer:
    """Kinesis Stream Consumer í´ë˜ìŠ¤"""

    def __init__(self):
        """ì´ˆê¸°í™” ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        self.kinesis_client = boto3.client("kinesis", region_name=settings.AWS_REGION)
        self.stream_name = settings.KINESIS_STREAM_NAME
        
        # ì™¸ë¶€ ì„œë¹„ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.milvus_client = MilvusClient()
        self.ai_client = AIClient()
        self.slack_notifier = SlackNotifier()
        self.dlq = S3DLQ()
        self.throttle = Throttle()
        
        # ìƒ¤ë“œ ê´€ë¦¬ë¥¼ ìœ„í•œ ìƒíƒœ
        self.shard_iterator = None

    def start(self):
        """Consumer ë©”ì¸ ë£¨í”„ ì‹œì‘"""
        logger.info(f"ğŸš€ Kinesis Consumer ì‹œì‘: {self.stream_name}")
        
        try:
            # 1. ìƒ¤ë“œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ë‹¨ì¼ ìƒ¤ë“œ ê°€ì •)
            response = self.kinesis_client.describe_stream(StreamName=self.stream_name)
            shard_id = response['StreamDescription']['Shards'][0]['ShardId']
            
            # 2. ìƒ¤ë“œ ì´í„°ë ˆì´í„° ìƒì„± (LATEST)
            self.shard_iterator = self.kinesis_client.get_shard_iterator(
                StreamName=self.stream_name,
                ShardId=shard_id,
                ShardIteratorType='LATEST'
            )['ShardIterator']
            
            # 3. í´ë§ ë£¨í”„
            while True:
                # [Aggregation] ìš”ì•½ ì•Œë¦¼ ì „ì†¡ (ë§¤ ë£¨í”„ë§ˆë‹¤ ì²´í¬)
                summaries = self.throttle.get_summaries_to_send()
                for s in summaries:
                    self.slack_notifier.send_summary_alert(
                        s['service'], s['message'], s['count'], s['duration']
                    )

                response = self.kinesis_client.get_records(
                    ShardIterator=self.shard_iterator,
                    Limit=10
                )
                
                records = response.get('Records', [])
                if records:
                    logger.info(f"ğŸ“¥ {len(records)}ê°œ ë ˆì½”ë“œ ìˆ˜ì‹ ")
                    self.process_records(records)
                
                # ë‹¤ìŒ ì´í„°ë ˆì´í„° ê°±ì‹ 
                self.shard_iterator = response.get('NextShardIterator')
                if not self.shard_iterator:
                    logger.warning("ShardIterator ë§Œë£Œë¨. ì¬ì—°ê²° í•„ìš”.")
                    break
                
                # AWS API ìŠ¤ë¡œí‹€ë§ ë°©ì§€
                time.sleep(1)
                
        except Exception as e:
            logger.error(f"Consumer ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            raise e

    def process_records(self, records: List[Dict[str, Any]]):
        """ë ˆì½”ë“œ ë°°ì¹˜ ì²˜ë¦¬"""
        for record in records:
            try:
                # 1. Kinesis ë°ì´í„° ë””ì½”ë”©
                raw_str = record["Data"].decode("utf-8")
                
                if "[DATA received from" in raw_str:
                    try:
                        raw_str = raw_str.split("]: ", 1)[1]
                    except IndexError:
                        logger.warning(f"ë©”íƒ€ë°ì´í„° ì œê±° ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {raw_str[:50]}...")

                raw_data = json.loads(raw_str)
                log_record = LogRecord(**raw_data)

                if log_record.level not in ["ERROR", "WARN"]:
                    continue

                logger.info(f"ğŸš¨ ì—ëŸ¬ ê°ì§€: {log_record.service} - {log_record.message}")
                
                # 4. RAG ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
                self._run_rag_pipeline(log_record)

            except ValidationError as e:
                logger.error(f"ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
            except json.JSONDecodeError as e:
                logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            except Exception as e:
                logger.error(f"ë ˆì½”ë“œ ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")

    def _run_rag_pipeline(self, log_record: LogRecord):
        """RAG ë¶„ì„ ë° ì•Œë¦¼ íŒŒì´í”„ë¼ì¸"""
        try:
            # 0. ìŠ¤ë¡œí‹€ë§ ì²´í¬ (First Alert ì—¬ë¶€ íŒë‹¨)
            if not self.throttle.record_occurrence(log_record.service, log_record.message):
                return

            # 1. ì„ë² ë”© ìƒì„±
            clean_query = clean_log_for_embedding(
                log_record.service, 
                log_record.message, 
                log_record.log_content
            )
            embedding = self.ai_client.create_embedding(clean_query)
            
            # 2. ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰
            similar_cases = self.milvus_client.search_similar_logs(embedding)
            
            # Cache Hit ë¡œì§
            best_match = None
            if similar_cases:
                top_case = similar_cases[0]
                if top_case.get('score') < 0.35:
                    best_match = top_case
                    logger.info(f"âš¡ [Cache Hit] ìœ ì‚¬ ì‚¬ë¡€ ë°œê²¬ (Distance: {top_case['score']:.4f})")

            rag_info = {}
            if best_match:
                analysis_result = {
                    "cause": f"[ê³¼ê±° ì‚¬ë¡€ ê¸°ë°˜ ìë™ ë¶„ì„] {best_match['cause']}",
                    "action": best_match['action'] 
                }
                rag_info = {
                    "source": "Cache Hit",
                    "distance": best_match['score'],
                    "similar_count": len(similar_cases)
                }
            else:
                if similar_cases:
                    logger.info(f"ğŸ” ìœ ì‚¬ ì‚¬ë¡€ {len(similar_cases)}ê±´ ë°œê²¬. AI ì •ë°€ ë¶„ì„ ìˆ˜í–‰.")
                
                start_time = time.time()
                analysis_result = self.ai_client.analyze_log(log_record.model_dump(), similar_cases)
                latency = time.time() - start_time
                
                rag_info = {
                    "source": "OpenAI",
                    "distance": similar_cases[0]['score'] if similar_cases else None,
                    "similar_count": len(similar_cases),
                    "latency": f"{latency:.2f}s"
                }

                self.dlq.save_rag_miss_log(log_record.model_dump(), analysis_result)
            
            # 3. ë°œìƒ íšŸìˆ˜ (ì´ ì‹œì ì—” ë¬´ì¡°ê±´ 1íšŒì°¨ First Alertì„)
            rag_info["occurrence_count"] = 1
            
            # 4. Slack ì•Œë¦¼ ì „ì†¡
            self.slack_notifier.send_alert(log_record.model_dump(), analysis_result, rag_info)
            
        except Exception as e:
            logger.error(f"RAG íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
