"""
=====================================================
Kinesis Stream Consumer
=====================================================
ì„¤ëª…: Kinesis Data Streamì—ì„œ ë¡œê·¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ êµ¬ë…
ì—­í• : ë°ì´í„° ìˆ˜ì‹  â†’ Pydantic ê²€ì¦ â†’ RAG ë¶„ì„ â†’ Slack ì•Œë¦¼
=====================================================
"""

import json
import time
from typing import Any, Dict, List

import boto3
from config.settings import settings
from models.log_schema import LogRecord
from pydantic import ValidationError
from services.milvus_client import MilvusClient
from services.openai_client import OpenAIClient
from services.s3_dlq import S3DLQ
from services.slack_notifier import SlackNotifier
from utils.logger import setup_logger

logger = setup_logger(__name__)


class KinesisConsumer:
    """Kinesis Stream Consumer í´ë˜ìŠ¤"""

    def __init__(self):
        """ì´ˆê¸°í™” ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        self.kinesis_client = boto3.client("kinesis", region_name=settings.AWS_REGION)
        self.stream_name = settings.KINESIS_STREAM_NAME
        
        # ì™¸ë¶€ ì„œë¹„ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.milvus_client = MilvusClient()
        self.ai_client = OpenAIClient()
        self.slack_notifier = SlackNotifier()
        self.dlq = S3DLQ()
        
        # ìƒ¤ë“œ ê´€ë¦¬ë¥¼ ìœ„í•œ ìƒíƒœ
        self.shard_iterator = None

    def start(self):
        """Consumer ë©”ì¸ ë£¨í”„ ì‹œì‘"""
        logger.info(f"ğŸš€ Kinesis Consumer ì‹œì‘: {self.stream_name}")
        
        try:
            # 1. ìƒ¤ë“œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ë‹¨ì¼ ìƒ¤ë“œ ê°€ì •, multi-shardì‹œ ë¡œì§ í™•ì¥ í•„ìš”)
            response = self.kinesis_client.describe_stream(StreamName=self.stream_name)
            shard_id = response['StreamDescription']['Shards'][0]['ShardId']
            
            # 2. ìƒ¤ë“œ ì´í„°ë ˆì´í„° ìƒì„± (LATEST: ì‹¤í–‰ ì‹œì  ì´í›„ ë°ì´í„°ë§Œ)
            self.shard_iterator = self.kinesis_client.get_shard_iterator(
                StreamName=self.stream_name,
                ShardId=shard_id,
                ShardIteratorType='LATEST'
            )['ShardIterator']
            
            # 3. í´ë§ ë£¨í”„
            while True:
                response = self.kinesis_client.get_records(
                    ShardIterator=self.shard_iterator,
                    Limit=10  # ë°°ì¹˜ ì‚¬ì´ì¦ˆ
                )
                
                records = response.get('Records', [])
                if records:
                    logger.info(f"ğŸ“¥ {len(records)}ê°œ ë ˆì½”ë“œ ìˆ˜ì‹ ")
                    self.process_records(records)
                
                # ë‹¤ìŒ ì´í„°ë ˆì´í„° ê°±ì‹ 
                self.shard_iterator = response.get('NextShardIterator')
                if not self.shard_iterator:
                    logger.warning("ShardIterator ë§Œë£Œë¨. ì¬ì—°ê²° í•„ìš”.")
                    break
                
                # AWS API ìŠ¤ë¡œí‹€ë§ ë°©ì§€
                time.sleep(1)
                
        except Exception as e:
            logger.error(f"Consumer ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            raise e

    def process_records(self, records: List[Dict[str, Any]]):
        """ë ˆì½”ë“œ ë°°ì¹˜ ì²˜ë¦¬"""
        for record in records:
            try:
                # 1. Kinesis ë°ì´í„° ë””ì½”ë”©
                raw_data = json.loads(record["Data"].decode("utf-8"))

                # 2. Pydantic ê²€ì¦
                log_record = LogRecord(**raw_data)

                # 3. ë ˆë²¨ í•„í„°ë§ (ERROR/WARNë§Œ ì²˜ë¦¬)
                if log_record.level not in ["ERROR", "WARN"]:
                    # INFO ë¡œê·¸ëŠ” ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ ì¶œë ¥
                    # logger.debug(f"â„¹ï¸ INFO ìŠ¤í‚µ: {log_record.service}")
                    continue

                logger.info(f"ğŸš¨ ì—ëŸ¬ ê°ì§€: {log_record.service} - {log_record.message}")
                
                # 4. RAG ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
                self._run_rag_pipeline(log_record)

            except ValidationError as e:
                logger.error(f"ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
                # DLQ ì €ì¥
                self.dlq.save_failed_record(raw_data, str(e))
                
            except json.JSONDecodeError as e:
                logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                self.dlq.save_failed_record({"raw_bytes": str(record["Data"])}, str(e))

            except Exception as e:
                logger.error(f"ë ˆì½”ë“œ ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")

    def _run_rag_pipeline(self, log_record: LogRecord):
        """RAG ë¶„ì„ ë° ì•Œë¦¼ íŒŒì´í”„ë¼ì¸"""
        try:
            # 1. ì„ë² ë”© ìƒì„± (ê²€ìƒ‰ìš© ì¿¼ë¦¬)
            # ë¡œê·¸ ë©”ì‹œì§€ì™€ ìƒì„¸ ë‚´ìš©ì„ ì¡°í•©í•˜ì—¬ ì¿¼ë¦¬ êµ¬ì„±
            query_text = f"{log_record.message} {log_record.log_content or ''}"[:8000]
            embedding = self.ai_client.create_embedding(query_text)
            
            # 2. ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ (Milvus)
            similar_cases = self.milvus_client.search_similar_logs(embedding)
            if similar_cases:
                logger.info(f"ğŸ” ìœ ì‚¬ ì‚¬ë¡€ {len(similar_cases)}ê±´ ë°œê²¬")
            
            # 3. AI ì›ì¸ ë¶„ì„ (OpenAI)
            analysis_result = self.ai_client.analyze_log(log_record.model_dump(), similar_cases)
            
            # 4. Slack ì•Œë¦¼ ì „ì†¡
            self.slack_notifier.send_alert(log_record.model_dump(), analysis_result)
            
            # 5. ìê°€ í•™ìŠµ (Auto-Learning)
            # ë¶„ì„ ì™„ë£Œëœ ë°ì´í„°ë¥¼ ë‹¤ì‹œ Milvusì— ì €ì¥í•˜ì—¬ ì§€ì‹ ì¶•ì 
            knowledge_data = log_record.model_dump()
            knowledge_data.update(analysis_result) # cause, action ì¶”ê°€
            self.milvus_client.insert_log_case(knowledge_data, embedding)
            
        except Exception as e:
            logger.error(f"RAG íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
