"""
=====================================================
Kinesis Stream Consumer
=====================================================
ì„¤ëª…: Kinesis Data Streamì—ì„œ ë¡œê·¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ êµ¬ë…
ì—­í• : ë°ì´í„° ìˆ˜ì‹  â†’ Pydantic ê²€ì¦ â†’ RAG ë¶„ì„ â†’ Slack ì•Œë¦¼
=====================================================
"""

import json
import time
from typing import Any, Dict, List

import boto3
from config.settings import settings
from models.log_schema import LogRecord
from pydantic import ValidationError
from services.milvus_client import MilvusClient
from services.openai_client import OpenAIClient
from services.s3_dlq import S3DLQ
from services.slack_notifier import SlackNotifier
from services.throttle import Throttle
from utils.logger import setup_logger
from utils.text_preprocessor import clean_log_for_embedding

logger = setup_logger(__name__)


class KinesisConsumer:
    """Kinesis Stream Consumer í´ë˜ìŠ¤"""

    def __init__(self):
        """ì´ˆê¸°í™” ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        self.kinesis_client = boto3.client("kinesis", region_name=settings.AWS_REGION)
        self.stream_name = settings.KINESIS_STREAM_NAME
        
        # ì™¸ë¶€ ì„œë¹„ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.milvus_client = MilvusClient()
        self.ai_client = OpenAIClient()
        self.slack_notifier = SlackNotifier()
        self.dlq = S3DLQ()
        self.throttle = Throttle()
        
        # ìƒ¤ë“œ ê´€ë¦¬ë¥¼ ìœ„í•œ ìƒíƒœ
        self.shard_iterator = None

    def start(self):
        """Consumer ë©”ì¸ ë£¨í”„ ì‹œì‘"""
        logger.info(f"ğŸš€ Kinesis Consumer ì‹œì‘: {self.stream_name}")
        
        try:
            # 1. ìƒ¤ë“œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ë‹¨ì¼ ìƒ¤ë“œ ê°€ì •, multi-shardì‹œ ë¡œì§ í™•ì¥ í•„ìš”)
            response = self.kinesis_client.describe_stream(StreamName=self.stream_name)
            shard_id = response['StreamDescription']['Shards'][0]['ShardId']
            
            # 2. ìƒ¤ë“œ ì´í„°ë ˆì´í„° ìƒì„± (LATEST: ì‹¤í–‰ ì‹œì  ì´í›„ ë°ì´í„°ë§Œ)
            self.shard_iterator = self.kinesis_client.get_shard_iterator(
                StreamName=self.stream_name,
                ShardId=shard_id,
                ShardIteratorType='LATEST'
            )['ShardIterator']
            
            # 3. í´ë§ ë£¨í”„
            while True:
                response = self.kinesis_client.get_records(
                    ShardIterator=self.shard_iterator,
                    Limit=10  # ë°°ì¹˜ ì‚¬ì´ì¦ˆ
                )
                
                records = response.get('Records', [])
                if records:
                    logger.info(f"ğŸ“¥ {len(records)}ê°œ ë ˆì½”ë“œ ìˆ˜ì‹ ")
                    self.process_records(records)
                
                # ë‹¤ìŒ ì´í„°ë ˆì´í„° ê°±ì‹ 
                self.shard_iterator = response.get('NextShardIterator')
                if not self.shard_iterator:
                    logger.warning("ShardIterator ë§Œë£Œë¨. ì¬ì—°ê²° í•„ìš”.")
                    break
                
                # AWS API ìŠ¤ë¡œí‹€ë§ ë°©ì§€
                time.sleep(1)
                
        except Exception as e:
            logger.error(f"Consumer ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            raise e

    def process_records(self, records: List[Dict[str, Any]]):
        """ë ˆì½”ë“œ ë°°ì¹˜ ì²˜ë¦¬"""
        for record in records:
            try:
                # 1. Kinesis ë°ì´í„° ë””ì½”ë”© ë° ì „ì²˜ë¦¬
                raw_str = record["Data"].decode("utf-8")
                
                # [DATA received from shardId...] ì ‘ë‘ì–´ ì œê±°
                if "[DATA received from" in raw_str:
                    try:
                        # ì ‘ë‘ì–´ ë’¤ì˜ ì‹¤ì œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                        # ì˜ˆ: "[DATA...] {"level":...}" -> "{"level":...}"
                        raw_str = raw_str.split("]: ", 1)[1]
                    except IndexError:
                        logger.warning(f"ë©”íƒ€ë°ì´í„° ì œê±° ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {raw_str[:50]}...")

                raw_data = json.loads(raw_str)

                # 2. Pydantic ê²€ì¦
                log_record = LogRecord(**raw_data)

                # 3. ë ˆë²¨ í•„í„°ë§ (ERROR/WARNë§Œ ì²˜ë¦¬)
                if log_record.level not in ["ERROR", "WARN"]:
                    # INFO ë¡œê·¸ëŠ” ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ ì¶œë ¥
                    # logger.debug(f"â„¹ï¸ INFO ìŠ¤í‚µ: {log_record.service}")
                    continue

                logger.info(f"ğŸš¨ ì—ëŸ¬ ê°ì§€: {log_record.service} - {log_record.message}")
                
                # 4. RAG ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
                self._run_rag_pipeline(log_record)

            except ValidationError as e:
                logger.error(f"ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
                # DLQ ì €ì¥
                self.dlq.save_failed_record(raw_data, str(e))
                
            except json.JSONDecodeError as e:
                logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                self.dlq.save_failed_record({"raw_bytes": str(record["Data"])}, str(e))

            except Exception as e:
                logger.error(f"ë ˆì½”ë“œ ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")

    def _run_rag_pipeline(self, log_record: LogRecord):
        """RAG ë¶„ì„ ë° ì•Œë¦¼ íŒŒì´í”„ë¼ì¸"""
        try:
            # 0. ìŠ¤ë¡œí‹€ë§ ì²´í¬ (ê³¼ë„í•œ ì•Œë¦¼ ë°©ì§€)
            if not self.throttle.should_send_alert(log_record.service, log_record.message):
                return

            # 1. ì„ë² ë”© ìƒì„± (ê²€ìƒ‰ìš© ì¿¼ë¦¬)
            # [RAG ìµœì í™”] í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì ìš© (ë…¸ì´ì¦ˆ ì œê±°)
            clean_query = clean_log_for_embedding(
                log_record.service, 
                log_record.message, 
                log_record.log_content
            )
            embedding = self.ai_client.create_embedding(clean_query)
            
            # 2. ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ (Milvus)
            similar_cases = self.milvus_client.search_similar_logs(embedding)
            
            # [RAG ìµœì í™”] ìœ ì‚¬ë„ê°€ ë§¤ìš° ë†’ì€(ê±°ë¦¬ ê°€ê¹Œìš´) ì‚¬ë¡€ê°€ ìˆìœ¼ë©´ AI í˜¸ì¶œ ìƒëµ
            # L2 Distance metric: 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬í•¨ (ì„ê³„ê°’: 0.35 ì„¤ì •)
            best_match = None
            if similar_cases:
                top_case = similar_cases[0]
                if top_case.get('score') < 0.35:
                    best_match = top_case
                    logger.info(f"âš¡ [Cache Hit] ìœ ì‚¬ ì‚¬ë¡€ ë°œê²¬ (Distance: {top_case['score']:.4f}). AI ë¶„ì„ ìƒëµ.")

            if best_match:
                # ìºì‹œëœ ë‹µë³€ ì‚¬ìš©
                analysis_result = {
                    "cause": f"[ê³¼ê±° ì‚¬ë¡€ ê¸°ë°˜ ìë™ ë¶„ì„] {best_match['cause']}",
                    "action": best_match['action'] 
                }
            else:
                # 3. AI ì›ì¸ ë¶„ì„ (OpenAI)
                if similar_cases:
                    logger.info(f"ğŸ” ìœ ì‚¬ ì‚¬ë¡€ {len(similar_cases)}ê±´ ë°œê²¬ (Distance: {similar_cases[0]['score']:.4f}). AI ì •ë°€ ë¶„ì„ ìˆ˜í–‰.")
                analysis_result = self.ai_client.analyze_log(log_record.model_dump(), similar_cases)
            
            # 4. Slack ì•Œë¦¼ ì „ì†¡
            self.slack_notifier.send_alert(log_record.model_dump(), analysis_result)
            
            # [ì‚­ì œë¨] ìê°€ í•™ìŠµ (Auto-Learning) ë¡œì§ ì œê±°ë¨ (User Request)
            
        except Exception as e:
            logger.error(f"RAG íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
