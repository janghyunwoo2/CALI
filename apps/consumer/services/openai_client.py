from openai import OpenAI
from config.settings import settings
from config.prompts import build_user_prompt
from utils.logger import setup_logger
import json

logger = setup_logger(__name__)

class OpenAIClient:
    def __init__(self):
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = "gpt-4o" # MVP ëª¨ë¸ ê³ ì •

    
    def create_embedding(self, text: str) -> list:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (text-embedding-3-small)"""
        try:
            response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    def analyze_log(self, current_log: dict, similar_cases: list = None) -> dict:
        try:
            # ì „ëµ ê²°ì • ë¡œì§ (Selector)
            # Tier 1 (Fast Path)ì€ ì—¬ê¸°ì„œ ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ (KinesisConsumerì—ì„œ ì²˜ë¦¬)
            # Tier 2 (Few-Shot): ìœ ì‚¬ ì‚¬ë¡€ê°€ ìˆê³ , ìœ ì‚¬ë„ê°€ ì¼ì • ìˆ˜ì¤€ ì´ìƒì¼ ë•Œ (Distance < 0.65)
            # Tier 3 (ReAct): ìœ ì‚¬ ì‚¬ë¡€ê°€ ì—†ê±°ë‚˜, ë§¤ìš° ë‹¤ë¥¼ ë•Œ (Distance >= 0.65)
            
            mode = "react"
            temperature = 0.5
            
            if similar_cases:
                # ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ë¡€ì˜ ê±°ë¦¬ê°’ í™•ì¸
                # Milvus L2: 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬í•¨
                best_score = similar_cases[0].get('score', 1.0)
                
                if best_score < 0.65:
                    mode = "few_shot"
                    temperature = 0.3 # ì‚¬ì‹¤ ê¸°ë°˜ ì‘ë‹µ
                    logger.info(f"ğŸ¤– AI ëª¨ë“œ: Few-Shot (ìœ ì‚¬ë„ ì–‘í˜¸: {best_score:.4f})")
                else:
                    mode = "react"
                    temperature = 0.7 # ì¶”ë¡ ì„ ìœ„í•´ ì°½ì˜ì„± í—ˆìš©
                    logger.info(f"ğŸ§  AI ëª¨ë“œ: ReAct (ìœ ì‚¬ë„ ë‚®ìŒ: {best_score:.4f})")
            else:
                mode = "react"
                temperature = 0.7
                logger.info("ğŸ§  AI ëª¨ë“œ: ReAct (ìœ ì‚¬ ì‚¬ë¡€ ì—†ìŒ)")

            # prompts.pyì—ì„œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            from config.prompts import get_system_prompt, build_user_prompt # ëŠ¦ì€ import (ìˆœí™˜ ì°¸ì¡° ë°©ì§€ ë“±)
            
            system_prompt = get_system_prompt(mode)
            user_prompt = build_user_prompt(current_log, similar_cases or [])
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                response_format={"type": "json_object"},
                temperature=temperature,
                timeout=10.0 # 10ì´ˆ íƒ€ì„ì•„ì›ƒ ê°•ì œ (SRE ì•ˆì •ì„±)
            )
            
            result = json.loads(response.choices[0].message.content)
            
            import re
            def format_list(items):
                if isinstance(items, list):
                    # ì´ë¯¸ ë²ˆí˜¸ê°€ ë§¤ê²¨ì ¸ ìˆë‹¤ë©´ ì œê±° (ì˜ˆ: "1. ì›ì¸" -> "ì›ì¸", "2 . ì›ì¸" -> "ì›ì¸")
                    cleaned_items = [re.sub(r'^\d+\s*[\.\)]\s*', '', item) for item in items]
                    return "\n\n".join([f"{i+1}. {item}" for i, item in enumerate(cleaned_items)])
                return str(items)

            if "cause" in result:
                result["cause"] = format_list(result["cause"])

            if "action_plan" in result:
                result["action"] = format_list(result["action_plan"])
            
            # ReAct ì¶”ë¡  ê³¼ì •ì´ ìˆë‹¤ë©´ ë©”íƒ€ë°ì´í„°ì— í¬í•¨í•  ìˆ˜ë„ ìˆìŒ (í˜„ì¬ëŠ” ë¦¬í„´ê°’ì— í¬í•¨ë¨)
            
            # ReAct ì¶”ë¡  ê³¼ì •ì´ ìˆë‹¤ë©´ ë©”íƒ€ë°ì´í„°ì— í¬í•¨í•  ìˆ˜ë„ ìˆìŒ (í˜„ì¬ëŠ” ë¦¬í„´ê°’ì— í¬í•¨ë¨)
            
            return result
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"cause": "AI Analysis Failed", "action": "Please check raw logs manually."}
